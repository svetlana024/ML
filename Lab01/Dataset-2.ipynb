{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Spotify Tracks Dataset"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"В качестве второго датасета я выбрала датасет \"Spotify Tracks DB\". Он включает различные характеристики треков с платформы Spotify, такие, как:\n\n    1. жанр (genre)\n    2. исполнитель (atrist_name)\n    3. название трека (track_name)\n    4. идентификатор трека (track_id)\n    5. популярность (popularity)\n    6. акустичность (acousticness)\n    7. танцевальность (danceability)\n    8. продолжительность [в милисекундах] (duration_ms)\n    9. энергичность (energy)\n    10. инструментальность (instrumentalness)\n    11. ключ (key)\n    12. живость (liveness)\n    13. громкость (loudness)\n    14. модальность (mode)\n    15. словестность (speechiness)\n    16. темп [кол-во ударов/ минута] (tempo)\n    17. временная сигнатруа [кол-во ударов/ бар] (time_signature)\n    18. валентность (valence)\n\nНа основе перечисленных характеристик, каждую из которых я еще разберу подробнее, можно сформулировать задачу следующим образом: **обучить модель, которая на основании перечисленных признаков и характеристик трека (некоторых или всех) сможет наилучшим образом предсказать значение валентности этого трека.** Под валентностью понимается некоторая мера, описывающая позитивность трека. Например, треки с высокой валентностью звучат более позитивно (например, счастливые, веселые, эйфоричные), в то время как треки с низкой валентностью звучат более негативно (например, грустные, подавленные, злые). \n\nТак, в качетсве целевого признака будем считать признак 'valence'.\nЧтобы разобраться, что перечисленные характеристики обозначают, и какие зависимости существуют между ними, рассмотрим датасет поближе."},{"metadata":{"trusted":true},"cell_type":"code","source":"spot_tracks_file_path = '../input/ultimate-spotify-tracks-db/SpotifyFeatures.csv'\ndata = pd.read_csv(spot_tracks_file_path)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe(include='all')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"В данных нет пропусков, т.к. признак count имеет одинаковое значение для всех колонок (характеристик). Часто фигурирует значение NaN из-за того, что для числовых признаков вычисляются самое распространенное значение (top), его частота (freq) и число уникальных признаков (unique) или же для объектных признаков (строки/ временные метки) вычисляются среднее значение (mean), среднеквадратичное значение (std), минимум (min), макисмум (max) и процентили (25, 50, 75%).\n\nПопробуем это исправить."},{"metadata":{},"cell_type":"markdown","source":"Сначала посмотрим на численные признаки. Их область значений и типы данных."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = []\nfor index in data.columns:\n    dtype = data[index].dtype\n    if dtype == int or dtype == float:\n        print(index, ' :', dtype, ' [', data[index].min(), ', ', data[index].max(), ']\\n')\n        features.append(index)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Если значение признака 'продолжительность трека' является вполне ясным, то такие признаки, как 'популярность', 'акустичность' или 'живость' требуют разъяснений. Описание этих признаков я нашла на сайте Spotify https://developer.spotify.com/documentation/web-api/reference/tracks/get-audio-features/).\n\nРассмотрим, что они значат и почему принимают именно такой диапозон значений."},{"metadata":{},"cell_type":"markdown","source":"* **популярность (popularity):** характеризует прослушиваемость трека, принимает значения от 0 до 100 в процентом соотношении.\n* **акустичность (acousticness):** показывает, является ли трек акустическим, принимает значения от 0.0 до 1.0. 1.0 представляет собой высокую вероятность того, что трек является акустическим.\n* **танцевальность (danceability):** описывает, насколько трек подходит для танцев. Предположение сновывается на комбинации музыкальных элементов, включая темп, стабильность ритма, силу удара и общую регулярность. Значение 0.0 соответствует наименее танцевальному треку, а 1.0 — наиболее танцевальному.\n* **энергичность (energy):** является перцептивной мерой интенсивности и активности, ринимает значения от 0.0 до 1.0. Как правило, энергичные треки кажутся быстрыми, громкими и шумными. Например, дэт-метал обладает высокой энергией (энергичность близится к 1.0), в то время как прелюдия Баха имеет низкие баллы по шкале (энергичность близка к 0.0). Перцептивные особенности, способствующие этому свойству, включают динамический диапазон, воспринимаемую громкость, тембр, скорость начала и общую энтропию.\n* **инструментальность (instrumentalness):** предсказывает, не содержит ли трек вокальные партии. В этом контексте звуки ”Ох“ и ”Aaa\" рассматриваются как инструментальные. Рэп или разговорные слова треков являются явно \"вокальными\". Чем ближе значение инструментальности к 1.0, тем больше вероятность того, что трек не содержит вокального содержания. Значения выше 0.5 предназначены для представления инструментальных треков, но вероятность выше, когда значение приближается к 1.0.\n* **живость (liveness):** обнаруживает присутствие \"живого звука\". Более высокие значения живости представляют собой повышенную вероятность того, что трек был выполнен вживую. Значение выше 0.8 обеспечивает высокую вероятность того, что трек был записан в режиме реального времени (live-выступление).\n* **громкость (loudness):** общая громкость трека в децибелах (дБ). Значения громкости усредняются по всей дорожке и полезны для сравнения относительной громкости дорожек. Громкость — это качество звука, которое является основным психологическим коррелятом физической силы (амплитуды). Типичные значения находятся в диапазоне от -60 до 0 дБ.\n* **словестность (speechiness):** обнаруживает присутствие произнесенных слов в треке. Чем более эксклюзивна речь, как запись (например, ток-шоу, аудиокнига, поэзия), тем ближе к 1.0 значение атрибута. Значения выше 0.66 описывают треки, которые, вероятно, полностью состоят из произносимых слов. Значения от 0.33 до 0.66 описывают треки, которые могут содержать как музыку, так и речь, либо в разрезе, либо слоисто, включая такие случаи, как рэп-музыка. Значения ниже 0,33, скорее всего, представляют собой музыку и другие не связанные с речью треки.\n* **темп [кол-во ударов/ минута] (tempo):** общий расчетный темп трека в ударах в минуту (BPM). В музыкальной терминологии темп — это скорость или темп данной пьесы, непосредственно вытекает из средней длительности ритма.\n* **временная сигнатруа [кол-во ударов/ бар] (time_signature):**  примерная общая временная сигнатура трека. Временная сигнатура (метр) - это нотационное соглашение, определяющее, сколько ударов приходится на каждый бар (или меру).\n* **валентность (valence):** мера от 0.0 до 1.0, описывающая музыкальную позитивность, передаваемую треком."},{"metadata":{},"cell_type":"markdown","source":"Распределение значений выглядит следующим образом."},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\ndata[features].hist(bins=50,figsize=(20,15))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Теперь рассмотрим категориальные признаки. Их область значений и типы данных."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe(include = ['O'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_col = []\nfor index in data.columns:\n    dtype = data[index].dtype\n    if dtype == object:\n        print(index, ' :', len(data[index].unique()), 'UNIQUE ELEMENTS \\n', dtype, data[index].unique(), '\\n')\n        cat_col.append(index)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Категориальных признаков значительно меньше. Значения большинства из них являются понятными, однако, лично для меня было загадкой, что означает 'key', 'mode' и 'time_signature'.\n\nОпять же обратимся к источнику Spotify."},{"metadata":{},"cell_type":"markdown","source":"* **ключ (key):** предполагаемый общий ключ трека. Целые числа сопоставляются с шагами, используя стандартную нотацию класса высоты тона. Например, 0 = C, 1 = C♯/D♭, 2 = D и так далее. Если ключ не был обнаружен, то значение равно -1.\n* **модальность (mode):** указывает на модальность (мажор или минор) трека, тип шкалы, из которой выводится его мелодическое содержание. Мажор представлен 1, а Минор 0.\n* **временная сигнатура (time_signature):** примерная общая временная сигнатура трека. Временная сигнатура (метр) - это нотационное соглашение, определяющее, сколько ударов приходится на каждый бар (или меру)."},{"metadata":{},"cell_type":"markdown","source":"Как выяснилось, на платформе Spotify все вышеперечисленные признаки принимают численные значения. Преобразуем наш датасет согласно всем указаниям."},{"metadata":{},"cell_type":"markdown","source":"Преобразуем значения ключа."},{"metadata":{"trusted":true},"cell_type":"code","source":"upd_data = data.copy(deep=True)\n\nupd_data.loc[upd_data['key'] == 'C', 'key'] = 0\nupd_data.loc[upd_data['key'] == 'C#', 'key'] = 1\nupd_data.loc[upd_data['key'] == 'D', 'key'] = 2\nupd_data.loc[upd_data['key'] == 'D#', 'key'] = 3\nupd_data.loc[upd_data['key'] == 'E', 'key'] = 4\nupd_data.loc[upd_data['key'] == 'F', 'key'] = 5\nupd_data.loc[upd_data['key'] == 'F#', 'key'] = 6\nupd_data.loc[upd_data['key'] == 'G', 'key'] = 7\nupd_data.loc[upd_data['key'] == 'G#', 'key'] = 8\nupd_data.loc[upd_data['key'] == 'A', 'key'] = 9\nupd_data.loc[upd_data['key'] == 'A#', 'key'] = 10\nupd_data.loc[upd_data['key'] == 'B', 'key'] = 11\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Преобразуем модальность."},{"metadata":{"trusted":true},"cell_type":"code","source":"upd_data.loc[upd_data['mode'] == 'Major', 'mode'] = 1\nupd_data.loc[upd_data['mode'] == 'Minor', 'mode'] = 0\nupd_data['mode'][0:5]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Преобразуем временную сигнатуру."},{"metadata":{"trusted":true},"cell_type":"code","source":"upd_data['time_signature'].unique()\nstring = []\nfor i in upd_data['time_signature'].unique():\n    for j in i.split(sep='/'):\n        string.append(int(j))\n    upd_data.loc[upd_data['time_signature'] == i, 'time_signature'] = string[0]/string[1]\n    string.clear()\nupd_data['time_signature'] =  pd.to_numeric(upd_data.time_signature, errors='coerce')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Теперь, когда все три категориальных признака преобразованы  в численные, рассмотрим принимаемые ими значения."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(cat_col)\nfor index in cat_col:\n    dtype = upd_data[index].dtype\n    if dtype == int or dtype == float:\n        print(index, ' :', dtype, ' [', upd_data[index].min(), ', ', upd_data[index].max(), ']\\n')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Построим их распределение."},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nupd_data[['key', 'mode', 'time_signature']].hist(bins=50,figsize=(20,15))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Категориальный признак 'track_id' я не считаю весомым при обучении модели, так что удалим его."},{"metadata":{"trusted":true},"cell_type":"code","source":"del upd_data['track_id']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"upd_data.describe(include=['O'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Построим распределение оставшихся категориальных признаков. В дальнейшем, для того, чтобы их использовать для обучения модели, их тоже придется конвертировать одним из способов."},{"metadata":{"trusted":true},"cell_type":"code","source":"upd_data['genre'].value_counts().plot.bar()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Несмотря на то, что признаки 'artist_name' и 'track_name' категориальные, они принимают значительно большое число уникальных значений. Поэтому постоить распределение значений не получается с помощью функции plot.bar — стек быстро переполняется. "},{"metadata":{"trusted":true},"cell_type":"code","source":"upd_data['artist_name'].head().value_counts().plot.bar()\n#upd_data['track_name'].value_counts().plot.bar()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Я решила сгенерировать новый численный признак, который будет упорядочивать выбранную категорию по какому-то признаку.\nПусть кодируемый признак – 'artist_name' (имя исполнителя), кодирующий признак – 'energy' (энергичность). Тогда новый признак будет описывать среднее значениее энергичности для каждого исполнителя."},{"metadata":{"trusted":true},"cell_type":"code","source":"def code_mean(data, cat_feature, real_feature):\n    return(data[cat_feature].map(data.groupby(cat_feature)[real_feature].mean()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"upd_data['artist_name_mean_energy'] = code_mean(upd_data, 'artist_name', 'energy')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Построим зависимость сгенерированного приизнака 'artist_name_mean_energy' и признака 'energy', выбранного в качестве кодирующего."},{"metadata":{"trusted":true},"cell_type":"code","source":"from pandas.plotting import scatter_matrix\nattributes = ['artist_name_mean_energy', 'energy']\nscatter_matrix(upd_data[attributes], figsize=(12, 8));","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"По графикам видно, что между ними прослеживается линейная зависимость.\nРаспределение 'artist_name_mean_energy' будет выглядеть следующим образом."},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nupd_data['artist_name_mean_energy'].hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def upd_num_cols(data, num_col):\n    for index in data.columns:\n        dtype = data[index].dtype\n        if (dtype == int or dtype == float) and index not in num_col:\n            num_col.append(index)\n    num_col.remove('valence')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Опытным путем я выяснила, что среднее значение отклонения минимально при следующих обучающих признаках."},{"metadata":{"trusted":true},"cell_type":"code","source":"features = ['popularity','danceability', 'duration_ms', 'energy', 'loudness', 'speechiness', 'instrumentalness', 'tempo', 'mode', 'time_signature','artist_name_mean_energy']\nX = upd_data[features]\ny = upd_data['valence']\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Как можно заметить, были убраны признаки 'key', 'liveness' и 'acousticness'."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\nprint(len(train_X), \"train +\", len(val_X), \"test\")\ntrain_X.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Будем в использовать алгоритм RandomForestRegressor() из sklearn.ensemble."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nst_model = RandomForestRegressor()\nst_model.fit(train_X, train_y)\nval_predictions = st_model.predict(val_X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error\nas_mae = mean_absolute_error(val_predictions, val_y)\nprint(val_predictions[0:5])\nprint(val_y.head().values)\nprint(\"Validation MAE: \", as_mae)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Среднее значение ошибки небольшое. Сотавляет около 10%. Проверим модель на всем датасете."},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = st_model.predict(X)\nas_mae = mean_absolute_error(predictions, y)\nprint(predictions[0:5])\nprint(y.head().values)\nprint(\"Validation MAE on all dataset: \", as_mae)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Посмотрим на корреляцию всех обучающих признаков. "},{"metadata":{"trusted":true},"cell_type":"code","source":"print(features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scatter_matrix(upd_data[features], figsize=(24, 16));","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Посмотрим на корреляцию обущающих признаков и целевого признака."},{"metadata":{"trusted":true},"cell_type":"code","source":"scatter_matrix(upd_data[['popularity','danceability','duration_ms','valence']], figsize=(12, 8));","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scatter_matrix(upd_data[['energy', 'instrumentalness', 'valence']], figsize=(12, 8))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scatter_matrix(upd_data[['loudness', 'speechiness', 'valence']], figsize=(12, 8))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scatter_matrix(upd_data[['tempo','mode', 'valence']], figsize=(12, 8))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scatter_matrix(upd_data[['time_signature','artist_name_mean_energy','valence']], figsize=(12, 8))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Посмотрим на корреляцию убранных признаков и целевого признака."},{"metadata":{"trusted":true},"cell_type":"code","source":"scatter_matrix(upd_data[['liveness', 'key', 'acousticness','valence']], figsize=(12, 8))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Проблемы, с которыми я стокнулась"},{"metadata":{},"cell_type":"markdown","source":"Я выбрала датасет \"Spotify Tracks DB\" и выделила целевой признак — \"валентность\", который может принимать значения в интервале [0.0, 1.0]. Соответсвенно, **моей задачей стало определение эмоциональной окраски трека** (степени его позитивности), согласна выбранным признакам. Далее, я рассмотрела все представленные признаки подробнее — убедилась, что в данных нет пропусков и нулевых значений. В отличие от предыдущего датасета, этот датасет включал изобилие численных признаков, каждый из которых каким-то образом характеризовал трек. Категориальных признаков было всего несколько. Такие признаки, как 'key', 'mode' и 'time_signature' я перекодировала в численные, согласно инструкциям на платформе Spotify. Категории 'track_name' и 'track_id' я не посчитала необходимым включать в тренировочную выборку, т.к. они не показались мне валидными в решении задачи — у каждого трека есть уникальный идентификатор и название (да, в датасете присутствовали повторяющиеся названия треков, но все таки уникальность была значительно высокой). Категорию 'artist_name' я упорядочила по признаку 'energy', тем самым сгенерировав новый численный признак 'artist_name_mean_energy', который будет описывать среднее значениее энергичности для каждого исполнителя. \n \nЯ построила зависимости всех признаков от целевого и опытным путем определила самые значимые признаки, необходимые для обучения модели. В конечную выборку я включила не все признаки — 'key', 'liveness', 'acousticness' не представили ценности при обучени модели. Таким образом, среднее значение ошибки для решение первоначальной задачи = 0.10. Это около 10%."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}